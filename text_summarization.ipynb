{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e24c09-3cd0-484e-8e17-dc2feb846bb0",
   "metadata": {},
   "source": [
    "# Text Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6dc6ed-5690-4127-9d21-b5cc7df2ca2a",
   "metadata": {},
   "source": [
    "## Import dependencies from transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a2c186-50e8-4f5a-bab3-35c54ce8bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c80485-3036-4d54-8a53-05131af49862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325223b8-e800-481c-9e35-ba1bcc536663",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeda9dbf-24fd-4c95-947c-b30f45963bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7114b0f-6a18-4f83-aca5-09cd1933d11e",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e0a4b0-e551-4476-8318-ce19d4e88117",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da5e0e-ae71-4df5-bf30-b2745d8f5a3e",
   "metadata": {},
   "source": [
    "## Perform abstractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58503498-db5c-4ca9-88be-b931a9fc8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Data science is an interdisciplinary academic field that uses statistics, \n",
    "scientific computing, scientific methods, processes, algorithms and \n",
    "systems to extract or extrapolate knowledge and insights from noisy, \n",
    "structured, and unstructured data.\n",
    "\n",
    "Data science also integrates domain knowledge from the underlying application \n",
    "domain (e.g., natural sciences, information technology, and medicine).\n",
    "Data science is multifaceted and can be described as a science, a \n",
    "research paradigm, a research method, a discipline, a workflow, and a \n",
    "profession.\n",
    "\n",
    "Data science is a \"concept to unify statistics, data analysis, informatics, \n",
    "and their related methods\" to \"understand and analyze actual phenomena\" \n",
    "with data. It uses techniques and theories drawn from many fields within \n",
    "the context of mathematics, statistics, computer science, information \n",
    "science, and domain knowledge.\n",
    "\n",
    "However, data science is different from computer science and information \n",
    "science. Turing Award winner Jim Gray imagined data science as \n",
    "a \"fourth paradigm\" of science (empirical, theoretical, computational, and \n",
    "now data-driven) and asserted that \"everything about science is changing \n",
    "because of the impact of information technology\" and the data deluge.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896b6fa-8f63-481c-9a9d-fc45f1ca816c",
   "metadata": {},
   "source": [
    "## Create tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093025ae-fe88-4deb-ad16-7e3e45221bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(text, truncation=True, padding='longest',return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b73f146-c4eb-4ebd-b98d-8b1fc0053cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2331,  1578,   117,   142,   115, 13920,  2232,   764,   120,  1481,\n",
       "          4412,   108,  3189,  6506,   108,  3189,  1625,   108,  1994,   108,\n",
       "          8970,   111,   747,   112,  5703,   132, 63533,   825,   111,  4275,\n",
       "           135, 16208,   108,  7314,   108,   111, 41831,   335,   107,  2331,\n",
       "          1578,   163, 15133,  2641,   825,   135,   109,  5910,   723,  2641,\n",
       "           143,   326,   107,   838,   107,   108,   710,  9059,   108,   257,\n",
       "           552,   108,   111,  3025,   250,  2331,  1578,   117, 35657,   111,\n",
       "           137,   129,  2540,   130,   114,  1578,   108,   114,   473, 17142,\n",
       "           108,   114,   473,  1356,   108,   114,  6270,   108,   114,  9901,\n",
       "           108,   111,   114,  5948,   107,  2331,  1578,   117,   114,   198,\n",
       "         33683,   112, 51573,  4412,   108,   335,  1382,   108, 52482,   108,\n",
       "           111,   153,   985,  1625,   194,   112,   198, 36169,   111,  5935,\n",
       "          1916, 16327,   194,   122,   335,   107,   168,  1481,  1739,   111,\n",
       "          9787,  4188,   135,   223,  2574,   373,   109,  2956,   113, 10045,\n",
       "           108,  4412,   108,   958,  1578,   108,   257,  1578,   108,   111,\n",
       "          2641,   825,   107,   611,   108,   335,  1578,   117,   291,   135,\n",
       "           958,  1578,   111,   257,  1578,   107, 61561,  2535,  2872,  4455,\n",
       "          7589, 10097,   335,  1578,   130,   114,   198, 40789, 17142,   194,\n",
       "           113,  1578,   143,  4192, 24684,  9458,   108,  9637,   108, 17264,\n",
       "           108,   111,   239,   335,   121,  6889,   158,   111, 27838,   120,\n",
       "           198, 29614,   160,  1578,   117,  1872,   262,   113,   109,   979,\n",
       "           113,   257,   552,   194,   111,   109,   335, 58505,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98094c-e34b-459a-b785-c77bdb5b8d4d",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d337fbd5-5a97-4d88-8a68-dd46b3e9876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630dd389-15f3-40d4-866f-b2e495a32614",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88c196a-6c6a-44b6-a476-28695d2709a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"_from_model_config\": true,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"forced_eos_token_id\": 1,\n",
       "  \"length_penalty\": 0.6,\n",
       "  \"max_length\": 64,\n",
       "  \"num_beams\": 8,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"transformers_version\": \"4.30.1\"\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2d64c1-b5c1-4c5f-b0cf-66b637ba9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66096cbc-8efd-4bd4-b715-7c4aaebbea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 2331, 1578,  117,  109,  692,  111, 1382,  113,  423, 3912,  113,\n",
       "          335,  107,    1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38cadb-6d21-4c97-b22f-0e96e06e7307",
   "metadata": {},
   "source": [
    "## Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba78f32-399e-4a30-9430-533f081d21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(summary[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c4d1794-ba07-4bf8-bb79-f2c48a4541f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data science is the study and analysis of large amounts of data.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b7d86-b27a-43aa-ae9c-7ac1cd4f6331",
   "metadata": {},
   "source": [
    "## Create function to wrap everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e15611-ab2b-477b-8008-a7c410a17692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarization(text):\n",
    "    tokens = tokenizer(text, truncation=True, padding='longest',return_tensors='pt')\n",
    "    summary = model.generate(**tokens)\n",
    "    output = tokenizer.decode(summary[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0de88876-f8c0-489c-ad44-ad3ce92918ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = text_summarization(\"My name is Nikhil Raj and I am a data scientist. I have total of 5 years of experience.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dd7b8cc-167b-4288-b791-46166ad9eff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello my name is Nikhil Raj and I am a data scientist.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312a1f3-afae-4dbe-9653-45c82d42431f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
